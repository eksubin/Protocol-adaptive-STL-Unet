{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:44:49.232850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-31 15:44:49.287861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-03-31 15:44:49.288283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 15:44:49.291798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-31 15:44:49.296006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-31 15:44:49.296593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-31 15:44:49.301615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-31 15:44:49.303481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-31 15:44:49.310149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-31 15:44:49.312171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-03-31 15:44:49.313056: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-03-31 15:44:49.325824: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz\n",
      "2022-03-31 15:44:49.329912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8578000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-31 15:44:49.329926: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-03-31 15:44:49.495623: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644cb974450 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-03-31 15:44:49.495660: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-03-31 15:44:49.498126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-03-31 15:44:49.498225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 15:44:49.498260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-03-31 15:44:49.498293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-03-31 15:44:49.498326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-03-31 15:44:49.498359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-03-31 15:44:49.498391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-03-31 15:44:49.498425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-31 15:44:49.502522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-03-31 15:44:49.502621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-03-31 15:44:49.507085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-31 15:44:49.507106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-03-31 15:44:49.507123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-03-31 15:44:49.511003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10203 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:d8:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import wandb\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from data import*\n",
    "\n",
    "######## for correcting the error from argon\n",
    "import tensorflow as tf\n",
    "# Config to turn on JIT compilation\n",
    "#config = tf.ConfigProto()\n",
    "#config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "#sess = tf.Session(config=config)\n",
    "####################\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"./output/ThreeLevel_CT_Inhouse.hdf5\")\n",
    "sys.path.append(os.getcwd()+'/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "#print(sys.path)\n",
    "print(len(model.layers)), #model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msubinek\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/erattakulangara/.conda/envs/chestXSeg/lib/python3.8/site-packages/IPython/html.py:12: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  warn(\"The `IPython.html` package has been deprecated since IPython 4.0. \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/subinek/ThreeLevel_CT_Inhouse_Storm_train/runs/adm4hqgw\" target=\"_blank\">royal-dew-10</a></strong> to <a href=\"https://wandb.ai/subinek/ThreeLevel_CT_Inhouse_Storm_train\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/subinek/ThreeLevel_CT_Inhouse_Storm_train/runs/adm4hqgw?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f86ec0f28e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parameters for each of the protocols\n",
    "\n",
    "RadialParams = { 'num_ep' : 60,\n",
    "                'num_step':100,\n",
    "                'num_layers': 18,\n",
    "                'learning_rate' : 1e-4,\n",
    "                'output_loc' : './NetworkOutput/Generic_Network_Testing/Radial',\n",
    "                'model_loc_loss' : './output/ThreeLevel_CT_Inhouse_Radial_loss.hdf5',\n",
    "                'model_loc' : './output/ThreeLevel_CT_Inhouse_Radial.hdf5',\n",
    "                'train_loc' : './data/Radial/Train/',\n",
    "                'val_loc' : './data/Radial/Val/',\n",
    "                'test_loc' : './data/Radial/Test/Image/',\n",
    "                'project' : 'ThreeLevel_CT_Inhouse_Radial'\n",
    "               }\n",
    "\n",
    "StormParams = {'num_ep' : 60,\n",
    "                'num_step':100,\n",
    "                'num_layers': 18,\n",
    "                'learning_rate' : 1e-3,\n",
    "                'output_loc' : './NetworkOutput/Generic_Network_Testing/Storm/',\n",
    "                'model_loc' : './output/ThreeLevel_CT_Inhouse_Storm_Thresholded.hdf5',\n",
    "                'train_loc' : './data/Storm/Train/',\n",
    "                'val_loc' : './data/Storm/Val/',\n",
    "                'test_loc' : './data/Storm/Test/TImage/',\n",
    "                'project' : 'ThreeLevel_CT_Inhouse_Storm_train',\n",
    "                'Image' : 'TImage',\n",
    "                'Label' : 'Airway'\n",
    "              }\n",
    "\n",
    "USCParams = {'num_ep' : 35,\n",
    "                'num_step':100,\n",
    "                'num_layers': 20,\n",
    "                'learning_rate' : 1e-4,\n",
    "                'output_loc' : './NetworkOutput/Generic_Network_Testing/USC/',\n",
    "                'model_loc' : './output/ThreeLevel_CT_Inhouse_USC.hdf5',\n",
    "                'train_loc' : './data/USC/Segmentations/Train',\n",
    "                'val_loc' : './data/USC/Segmentations/Val',\n",
    "                'test_loc' : './data/USC/Segmentations/Test/Image',\n",
    "                'project' : 'ThreeLevel_CT_Inhouse_USC',\n",
    "                'Image' : 'Image',\n",
    "                'Label' : 'Airway'\n",
    "}\n",
    "\n",
    "Params = StormParams\n",
    "wandb.init(project=Params['project'], entity=\"subinek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new folder path\n",
    "if not os.path.exists(Params['output_loc']):\n",
    "    os.makedirs(output_loc)\n",
    "    print('done')\n",
    "\n",
    "\n",
    "# Freezing layers\n",
    "for i in range(0,Params['num_layers']):\n",
    "    model.layers[i].trainable = False\n",
    "    \n",
    "start_val = Params['num_layers']\n",
    "end_val = len(model.layers)\n",
    "for i in range(start_val,end_val):\n",
    "    model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non - sweep config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 1 classes.\n",
      "Found 20 images belonging to 1 classes.\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 15:46:47.287811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-03-31 15:46:48.871445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9787Found 3 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05926, saving model to ./output/ThreeLevel_CT_Inhouse_Storm_Thresholded.hdf5\n",
      "100/100 [==============================] - 8s 77ms/step - loss: 0.0627 - accuracy: 0.9787 - val_loss: 0.0593 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9875\n",
      "Epoch 00002: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0296 - accuracy: 0.9875 - val_loss: 0.0593 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9906\n",
      "Epoch 00003: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.0222 - accuracy: 0.9906 - val_loss: 0.0735 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9924\n",
      "Epoch 00004: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.0179 - accuracy: 0.9924 - val_loss: 0.0931 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9934\n",
      "Epoch 00005: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0155 - accuracy: 0.9934 - val_loss: 0.0893 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9941\n",
      "Epoch 00006: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0138 - accuracy: 0.9941 - val_loss: 0.1149 - val_accuracy: 0.9738 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9946\n",
      "Epoch 00007: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 54ms/step - loss: 0.0126 - accuracy: 0.9946 - val_loss: 0.0994 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9950\n",
      "Epoch 00008: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.1040 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9953\n",
      "Epoch 00009: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.1246 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9955\n",
      "Epoch 00010: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.1245 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 11/60\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9957\n",
      "Epoch 00011: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.0101 - accuracy: 0.9957 - val_loss: 0.1413 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 12/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9958\n",
      "Epoch 00012: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 0.1259 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 13/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9960\n",
      "Epoch 00013: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0094 - accuracy: 0.9960 - val_loss: 0.1225 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 14/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9962\n",
      "Epoch 00014: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0088 - accuracy: 0.9962 - val_loss: 0.1239 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 15/60\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9963\n",
      "Epoch 00015: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1435 - val_accuracy: 0.9745 - lr: 1.0000e-04\n",
      "Epoch 16/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9963\n",
      "Epoch 00016: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0085 - accuracy: 0.9963 - val_loss: 0.1293 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 17/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9965\n",
      "Epoch 00017: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0082 - accuracy: 0.9965 - val_loss: 0.1459 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 18/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9964\n",
      "Epoch 00018: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0083 - accuracy: 0.9964 - val_loss: 0.1604 - val_accuracy: 0.9717 - lr: 1.0000e-04\n",
      "Epoch 19/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 00019: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0080 - accuracy: 0.9966 - val_loss: 0.1276 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 20/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9967\n",
      "Epoch 00020: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.1556 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 21/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n",
      "Epoch 00021: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0073 - accuracy: 0.9969 - val_loss: 0.1429 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 22/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9968\n",
      "Epoch 00022: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.1342 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 23/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9968\n",
      "Epoch 00023: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.1564 - val_accuracy: 0.9775 - lr: 1.0000e-04\n",
      "Epoch 24/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969\n",
      "Epoch 00024: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0071 - accuracy: 0.9969 - val_loss: 0.1356 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 25/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9970\n",
      "Epoch 00025: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.1277 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 26/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9958\n",
      "Epoch 00026: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 0.1018 - val_accuracy: 0.9804 - lr: 1.0000e-04\n",
      "Epoch 27/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9968\n",
      "Epoch 00027: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0074 - accuracy: 0.9968 - val_loss: 0.1460 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 28/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9967\n",
      "Epoch 00028: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 0.1354 - val_accuracy: 0.9752 - lr: 1.0000e-04\n",
      "Epoch 29/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 00029: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 0.1445 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 30/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9971\n",
      "Epoch 00030: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 0.1485 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 31/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 00031: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.1304 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 32/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 00032: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 0.1386 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 33/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n",
      "Epoch 00033: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.1497 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 34/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 00034: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.1529 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 35/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n",
      "Epoch 00035: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.8487 - val_accuracy: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 36/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9957\n",
      "Epoch 00036: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.1274 - val_accuracy: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 37/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972\n",
      "Epoch 00037: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.1343 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 38/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9973\n",
      "Epoch 00038: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 0.1314 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 39/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9973\n",
      "Epoch 00039: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 0.1411 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 40/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9971\n",
      "Epoch 00040: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.1535 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 41/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9975\n",
      "Epoch 00041: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.1627 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 42/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 00042: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.1368 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 43/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9974\n",
      "Epoch 00043: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.1371 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 44/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9975\n",
      "Epoch 00044: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.1210 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 45/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9975\n",
      "Epoch 00045: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0057 - accuracy: 0.9975 - val_loss: 0.1316 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 46/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 00046: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.1291 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 47/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9976\n",
      "Epoch 00047: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.1399 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 48/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9976\n",
      "Epoch 00048: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.1337 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 49/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 00049: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.1376 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 50/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 00050: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.1430 - val_accuracy: 0.9761 - lr: 1.0000e-04\n",
      "Epoch 51/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 00051: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.1449 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 52/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 00052: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.1409 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 53/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 00053: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.1553 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 54/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9968\n",
      "Epoch 00054: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 53ms/step - loss: 0.0082 - accuracy: 0.9968 - val_loss: 0.1425 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 55/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.1468 - val_accuracy: 0.9782 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9978\n",
      "Epoch 00056: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.1506 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 57/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9978\n",
      "Epoch 00057: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.1513 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 58/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 00058: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.1507 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 59/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 00059: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.1496 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 60/60\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9979\n",
      "Epoch 00060: val_loss did not improve from 0.05926\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.1536 - val_accuracy: 0.9775 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "myGene = trainGenerator(2,Params['train_loc'],Params['Image'],Params['Label'],data_gen_args,save_to_dir = None)\n",
    "\n",
    "myVal = trainGenerator(2,Params['val_loc'],Params['Image'],Params['Label'],data_gen_args,save_to_dir = None)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(Params['model_loc'], monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=4, \n",
    "                                       verbose=1, mode='auto', min_lr=0.001)\n",
    "\n",
    "h=model.fit_generator(myGene,validation_data = myVal,validation_steps = 1,steps_per_epoch=Params['num_step'],epochs=Params['num_ep'],callbacks=[model_checkpoint, reduce_lr, WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Generated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(Params['model_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_2335/3156597488.py:9: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "10/10 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# test module is been uploaded from the data.py file\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+'/code')\n",
    "\n",
    "from data import*\n",
    "\n",
    "test_generator = testGenerator(Params['test_loc'],0,10,target_size=(256,256))\n",
    "output = model.predict_generator(test_generator,10,verbose=1)\n",
    "saveResult(Params['output_loc'],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/erattakulangara/hpchome/DeepLearningAlgo/2022-Protocol-Adaptive_multiArtSegmentation'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestXSeg",
   "language": "python",
   "name": "chestxseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
